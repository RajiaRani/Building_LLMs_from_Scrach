{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b7cab49",
   "metadata": {},
   "source": [
    "### DATA SAMPLING WITH SLIDING WINDOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdf61ea",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "In this section we implement a data loader that fetches the input-target pairs using a sliding window approach.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e7aedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tiktoken in /Users/abroadhub/Library/Python/3.9/lib/python/site-packages (0.12.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/abroadhub/Library/Python/3.9/lib/python/site-packages (from tiktoken) (2025.9.18)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/abroadhub/Library/Python/3.9/lib/python/site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/abroadhub/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/abroadhub/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/abroadhub/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/abroadhub/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c212e163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version 0.12.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import  tiktoken\n",
    "print(\"tiktoken version\" , importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b22e720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59bf5f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "To get started, we will first tokenize the whole The Verdict short story we worked with\n",
    "earlier using the BPE tokenizer introduced in the previous section:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab8d688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5409dd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Executing the code above will return 5145, the total number of tokens in the training set,\n",
    "after applying the BPE tokenizer.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ef888b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Next, we remove the first 50 tokens from the dataset for demonstration purposes as it\n",
    "results in a slightly more interesting text passage in the next steps:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54c3e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the first 50 tokens for more clarity\n",
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65442198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5095\n"
     ]
    }
   ],
   "source": [
    "print(len(enc_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a27fb6c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "One of the easiest and most intuitive ways to create the input-target pairs for the nextword prediction task is to create two variables, x and y, where x contains the input tokens\n",
    "and y contains the targets, which are the inputs shifted by 1:</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b84d13b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "The context size determines how many tokens are included in the input\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61bc63bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [290, 4920, 2241, 287]\n",
      "Y: [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4 #length of the input\n",
    "# The context_size of 4 means that the model is trained to look at a sequence of 4 words(or tokens)\n",
    "# To predict the next word(token) in the sequence\n",
    "# The input X is the first 4 tokens [1,2,3,4] and the target(output) Y is the next tokens [2,3,4,5]\n",
    "\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "\n",
    "print(f\"X: {x}\")\n",
    "print(f\"Y: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bb81ba",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Processing the inputs along with the targets, which are the inputs shifted by one position,\n",
    "we can then create the next-word prediction tasks as\n",
    "follows:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4d53d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] -----> 4920\n",
      "[290, 4920] -----> 2241\n",
      "[290, 4920, 2241] -----> 287\n",
      "[290, 4920, 2241, 287] -----> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    print(context, \"----->\", desired)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f4fcde",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Everything left of the arrow (---->) refers to the input an LLM would receive, and the token\n",
    "ID on the right side of the arrow represents the target token ID that the LLM is supposed to\n",
    "predict.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7653991e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "For illustration purposes, let's repeat the previous code but convert the token IDs into\n",
    "text:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5db76d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ------>  established\n",
      " and established ------>  himself\n",
      " and established himself ------>  in\n",
      " and established himself in ------>  a\n"
     ]
    }
   ],
   "source": [
    "for i in range (1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    print(tokenizer.decode(context), \"------>\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7d4ec7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "We've now created the input-target pairs that we can turn into use for the LLM training in\n",
    "upcoming chapters.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91ed519",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "There's only one more task before we can turn the tokens into embeddings:implementing an efficient data loader that\n",
    "iterates over the input dataset and returns the inputs and targets as PyTorch tensors, which\n",
    "can be thought of as multidimensional arrays.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be8320",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "In particular, we are interested in returning two tensors: an input tensor containing the\n",
    "text that the LLM sees and a target tensor that includes the targets for the LLM to predict,\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a903819c",
   "metadata": {},
   "source": [
    "### IMPLEMENTING A DATA LOADER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ed94c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "For the efficient data loader implementation, we will use PyTorch's built-in Dataset and\n",
    "DataLoader classes.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d22a177",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Step 1: Tokenize the entire text\n",
    "    \n",
    "Step 2: Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "\n",
    "Step 3: Return the total number of rows in the dataset\n",
    "\n",
    "Step 4: Return a single row from the dataset\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ad46a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = [] # input\n",
    "        self.target_ids = [] # output\n",
    "\n",
    "        # Tokenizer the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "      # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids)-max_length, stride):\n",
    "            input_chunk = token_ids[i: i+max_length]\n",
    "            target_chunk = token_ids[i+1: i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27754ff",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "The GPTDatasetV1 class in listing 2.5 is based on the PyTorch Dataset class.\n",
    "\n",
    "It defines how individual rows are fetched from the dataset. \n",
    "\n",
    "Each row consists of a number of\n",
    "token IDs (based on a max_length) assigned to an input_chunk tensor. \n",
    "\n",
    "The target_chunk\n",
    "tensor contains the corresponding targets. \n",
    "\n",
    "I recommend reading on to see how the data\n",
    "returned from this dataset looks like when we combine the dataset with a PyTorch\n",
    "DataLoader -- this will bring additional intuition and clarity.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe99f85",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "The following code will use the GPTDatasetV1 to load the inputs in batches via a PyTorch\n",
    "DataLoader:</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ace37d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Step 1: Initialize the tokenizer\n",
    "\n",
    "Step 2: Create dataset\n",
    "\n",
    "Step 3: drop_last=True drops the last batch if it is shorter than the specified batch_size to prevent loss spikes\n",
    "during training\n",
    "\n",
    "Step 4: The number of CPU processes to use for preprocessing\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "445669ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    \n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    #create dataLoader\n",
    "    dataloader = DataLoader(\n",
    "       dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbe3535",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "Let's test the dataloader with a batch size of 1 for an LLM with a context size of 4, \n",
    "\n",
    "This will develop an intuition of how the GPTDatasetV1 class and the\n",
    "create_dataloader_v1 function work together: </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11ce8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66111898",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Convert dataloader into a Python iterator to fetch the next entry via Python's built-in next() function\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edc445b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0\n",
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdcadb4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "The first_batch variable contains two tensors: the first tensor stores the input token IDs,\n",
    "and the second tensor stores the target token IDs. \n",
    "\n",
    "Since the max_length is set to 4, each of the two tensors contains 4 token IDs. \n",
    "\n",
    "Note that an input size of 4 is relatively small and only chosen for illustration purposes. It is common to train LLMs with input sizes of at least\n",
    "256.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea68cb99",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "To illustrate the meaning of stride=1, let's fetch another batch from this dataset: </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "288aa536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0ce351",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "If we compare the first with the second batch, we can see that the second batch's token\n",
    "IDs are shifted by one position compared to the first batch. \n",
    "\n",
    "For example, the second ID in\n",
    "the first batch's input is 367, which is the first ID of the second batch's input. \n",
    "\n",
    "The stride\n",
    "setting dictates the number of positions the inputs shift across batches, emulating a sliding\n",
    "window approach\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385ade67",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "Batch sizes of 1, such as we have sampled from the data loader so far, are useful for\n",
    "illustration purposes. \n",
    "                                                                                 \n",
    "If you have previous experience with deep learning, you may know\n",
    "that small batch sizes require less memory during training but lead to more noisy model\n",
    "updates.\n",
    "\n",
    "Just like in regular deep learning, the batch size is a trade-off and hyperparameter\n",
    "to experiment with when training LLMs.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c1ff8e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "Before we move on to the two final sections of this chapter that are focused on creating\n",
    "the embedding vectors from the token IDs, let's have a brief look at how we can use the\n",
    "data loader to sample with a batch size greater than 1: </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3638a1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464,  1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026, 15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438,   568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502,   284,  3285,   326,    11],\n",
      "        [  287,   262,  6001,   286,   465, 13476,    11,   339],\n",
      "        [  550,  5710,   465, 12036,    11,  6405,   257,  5527],\n",
      "        [27075,    11,   290,  4920,  2241,   287,   257,  4489],\n",
      "        [   64,   319,   262, 34686, 41976,    13,   357, 10915]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807,  3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632,   438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568,   340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284,  3285,   326,    11,   287],\n",
      "        [  262,  6001,   286,   465, 13476,    11,   339,   550],\n",
      "        [ 5710,   465, 12036,    11,  6405,   257,  5527, 27075],\n",
      "        [   11,   290,  4920,  2241,   287,   257,  4489,    64],\n",
      "        [  319,   262, 34686, 41976,    13,   357, 10915,   314]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=8, stride=8, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77882625",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Note that we increase the stride to 4. This is to utilize the data set fully (we don't skip a\n",
    "single word) but also avoid any overlap between the batches, since more overlap could lead\n",
    "to increased overfitting.\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
