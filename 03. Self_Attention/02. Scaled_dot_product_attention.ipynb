{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c44385b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "inputs = torch.tensor([\n",
    "    [0.43, 0.15, 0.89], # Your\n",
    "    [0.55, 0.87, 0.66], # journey\n",
    "    [0.57, 0.85, 0.64], # starts\n",
    "    [0.22, 0.58, 0.33], # with\n",
    "    [0.77, 0.25, 0.10], # one\n",
    "    [0.05, 0.80, 0.55] # step\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be027eac",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "#A The second input element\n",
    "\n",
    "#B The input embedding size, d=3\n",
    "\n",
    "\n",
    "#C The output embedding size, d_out=2\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5906a22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5500, 0.8700, 0.6600])\n"
     ]
    }
   ],
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2\n",
    "print(x_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b6df85",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Note that in GPT-like models, the input and output dimensions are usually the same. \n",
    "\n",
    "But for illustration purposes, to better follow the computation, we choose different input (d_in=3)\n",
    "and output (d_out=2) dimensions here.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d497e0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Next, we initialize the three weight matrices Wq, Wk and Wv\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65efdaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "# print(W_query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "119dee6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query matrics:  Parameter containing:\n",
      "tensor([[0.2961, 0.5166],\n",
      "        [0.2517, 0.6886],\n",
      "        [0.0740, 0.8665]])\n",
      "---------------------------------------------\n",
      "Key matrics:  Parameter containing:\n",
      "tensor([[0.1366, 0.1025],\n",
      "        [0.1841, 0.7264],\n",
      "        [0.3153, 0.6871]])\n",
      "---------------------------------------------\n",
      "Value matrics:  Parameter containing:\n",
      "tensor([[0.0756, 0.1966],\n",
      "        [0.3164, 0.4017],\n",
      "        [0.1186, 0.8274]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Query matrics: \", W_query)\n",
    "print(\"---\"*15)\n",
    "print(\"Key matrics: \", W_key)\n",
    "print(\"---\"*15)\n",
    "print(\"Value matrics: \", W_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db426232",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Note that we are setting requires_grad=False to reduce clutter in the outputs for\n",
    "illustration purposes. \n",
    "\n",
    "If we were to use the weight matrices for model training, we\n",
    "would set requires_grad=True to update these matrices during model training.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a653e4fc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Next, we compute the query, key, and value vectors as shown earlier\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "448f8c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 2 Query value:  tensor([0.4306, 1.4551])\n",
      "---------------------------------------------\n",
      "Input 2 key value:  tensor([0.4433, 1.1419])\n",
      "---------------------------------------------\n",
      "Input 2  value vector:  tensor([0.3951, 1.0037])\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "print(\"Input 2 Query value: \", query_2)\n",
    "print(\"---\"*15)\n",
    "\n",
    "key_2 = x_2 @ W_key\n",
    "print(\"Input 2 key value: \", key_2)\n",
    "print(\"---\"*15)\n",
    "\n",
    "value_2 = x_2 @ W_value\n",
    "print(\"Input 2  value vector: \", value_2)\n",
    "print(\"---\"*15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a89c82",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "As we can see based on the output for the query, this results in a 2-dimensional vector. \n",
    "\n",
    "This is because: we set the number of columns of the corresponding weight matrix, via d_out, to 2:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e694b4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Even though our temporary goal is to only compute the one context vector z(2),  we still\n",
    "require the key and value vectors for all input elements. \n",
    "\n",
    "This is because they are involved in computing the attention weights with respect to the query q(2)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e0a8c9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "We can obtain all keys and values via matrix multiplication:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63b500f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 2])\n",
      "queries.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "queries = inputs @ W_query\n",
    "values = inputs @ W_value\n",
    "\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"queries.shape:\", queries.shape)\n",
    "print(\"values.shape:\", values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d38c791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3669, 0.7646],\n",
      "        [0.4433, 1.1419],\n",
      "        [0.4361, 1.1156],\n",
      "        [0.2408, 0.6706],\n",
      "        [0.1827, 0.3292],\n",
      "        [0.3275, 0.9642]])\n"
     ]
    }
   ],
   "source": [
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d43af015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1855, 0.8812],\n",
       "        [0.3951, 1.0037],\n",
       "        [0.3879, 0.9831],\n",
       "        [0.2393, 0.5493],\n",
       "        [0.1492, 0.3346],\n",
       "        [0.3221, 0.7863]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40e53096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2309, 1.0966],\n",
       "        [0.4306, 1.4551],\n",
       "        [0.4300, 1.4343],\n",
       "        [0.2355, 0.7990],\n",
       "        [0.2983, 0.6565],\n",
       "        [0.2568, 1.0533]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0177a388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "query_2 = queries[1]\n",
    "attention_score_22 = query_2 @ keys.T\n",
    "print(attention_score_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d282a712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9231, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],\n",
      "        [1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],\n",
      "        [1.2544, 1.8284, 1.7877, 1.0654, 0.5508, 1.5238],\n",
      "        [0.6973, 1.0167, 0.9941, 0.5925, 0.3061, 0.8475],\n",
      "        [0.6114, 0.8819, 0.8626, 0.5121, 0.2707, 0.7307],\n",
      "        [0.8995, 1.3165, 1.2871, 0.7682, 0.3937, 1.0996]])\n"
     ]
    }
   ],
   "source": [
    "final_attention_scores = queries @ keys.T\n",
    "print(final_attention_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a092389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "d_k = keys.shape[-1]\n",
    "attention_weights_2 = torch.softmax(attention_score_22 / d_k**0.5, dim=-1)\n",
    "print(attention_weights_2)\n",
    "print(d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a7083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5330, 0.7820, 0.7645, 0.4567, 0.2328, 0.6541],\n",
      "        [0.7335, 1.0695, 1.0456, 0.6233, 0.3220, 0.8914],\n",
      "        [0.7242, 1.0556, 1.0321, 0.6151, 0.3180, 0.8797],\n",
      "        [0.4026, 0.5870, 0.5739, 0.3421, 0.1767, 0.4893],\n",
      "        [0.3530, 0.5092, 0.4980, 0.2957, 0.1563, 0.4219],\n",
      "        [0.5193, 0.7601, 0.7431, 0.4435, 0.2273, 0.6349]])\n"
     ]
    }
   ],
   "source": [
    "d_k = inputs.shape[-1]\n",
    "scaled_scores = final_attention_scores / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
    "print(scaled_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f20d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weight = torch.softmax(scaled_scores, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8cef6a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1577, 0.2024, 0.1988, 0.1462, 0.1168, 0.1781],\n",
       "        [0.1540, 0.2154, 0.2104, 0.1379, 0.1020, 0.1803],\n",
       "        [0.1542, 0.2148, 0.2098, 0.1383, 0.1027, 0.1802],\n",
       "        [0.1608, 0.1934, 0.1908, 0.1514, 0.1283, 0.1754],\n",
       "        [0.1623, 0.1897, 0.1876, 0.1532, 0.1333, 0.1739],\n",
       "        [0.1582, 0.2013, 0.1979, 0.1467, 0.1182, 0.1776]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8a8ba57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weight[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da3c28e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1577, 0.2024, 0.1988, 0.1462, 0.1168, 0.1781],\n",
      "        [0.1540, 0.2154, 0.2104, 0.1379, 0.1020, 0.1803],\n",
      "        [0.1542, 0.2148, 0.2098, 0.1383, 0.1027, 0.1802],\n",
      "        [0.1608, 0.1934, 0.1908, 0.1514, 0.1283, 0.1754],\n",
      "        [0.1623, 0.1897, 0.1876, 0.1532, 0.1333, 0.1739],\n",
      "        [0.1582, 0.2013, 0.1979, 0.1467, 0.1182, 0.1776]])\n"
     ]
    }
   ],
   "source": [
    "d_k= inputs.shape[-1]\n",
    "attention_weight = torch.softmax(final_attention_scores/d_k**0.5, dim=-1)\n",
    "print(attention_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dbaa7f",
   "metadata": {},
   "source": [
    "## IMPLEMENTING A COMPACT SELF ATTENTION PYTHON CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4c6016",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "In the previous sections, we have gone through a lot of steps to compute the self-attention\n",
    "outputs. \n",
    "\n",
    "This was mainly done for illustration purposes so we could go through one step at\n",
    "a time. \n",
    "\n",
    "In practice, with the LLM implementation in the next chapter in mind, it is helpful to\n",
    "organize this code into a Python class as follows:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e86679e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "class SelfAttention_v1(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        query = x @ self.W_query\n",
    "        key = x @ self.W_key\n",
    "        value = x @ self.W_value\n",
    "\n",
    "        attention_scores = query @ key.T\n",
    "        attention_weights = torch.softmax(\n",
    "            attention_scores / key.shape[-1]**0.5 , dim=-1\n",
    "        )\n",
    "\n",
    "        context_vector = attention_weights @ value\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82effe81",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "In this PyTorch code, SelfAttention_v1 is a class derived from nn.Module, which is a\n",
    "fundamental building block of PyTorch models, which provides necessary functionalities for\n",
    "model layer creation and management.    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c587b754",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "The __init__ method initializes trainable weight matrices (W_query, W_key, and\n",
    "W_value) for queries, keys, and values, each transforming the input dimension d_in to an\n",
    "output dimension d_out.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa3e03",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "During the forward pass, using the forward method, we compute the attention scores\n",
    "(attn_scores) by multiplying queries and keys, normalizing these scores using softmax.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b5936",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "Finally, we create a context vector by weighting the values with these normalized attention\n",
    "scores.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e11297e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d3fd83",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Since inputs contains six embedding vectors, we get a matrix storing the six\n",
    "context vectors, as shown in the above result. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf726e2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "As a quick check, notice how the second row ([0.3061, 0.8210]) matches the contents of\n",
    "context_vec_2 in the previous section.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3bb4b8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "We can improve the SelfAttention_v1 implementation further by utilizing PyTorch's\n",
    "nn.Linear layers, which effectively perform matrix multiplication when the bias units are\n",
    "disabled. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d77e430",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "Additionally, a significant advantage of using nn.Linear instead of manually\n",
    "implementing nn.Parameter(torch.rand(...)) is that nn.Linear has an optimized weight\n",
    "initialization scheme, contributing to more stable and effective model training.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4a59c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9818de",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "You can use the SelfAttention_v2 similar to SelfAttention_v1:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e19810d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76386b2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Note that SelfAttention_v1 and SelfAttention_v2 give different outputs because they\n",
    "use different initial weights for the weight matrices since nn.Linear uses a more\n",
    "sophisticated weight initialization scheme.\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
